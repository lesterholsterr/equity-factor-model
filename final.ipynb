{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_original = pd.read_sas(\"merged_df.sas7bdat\", encoding='ISO-8859-1')\n",
    "signals_original = pd.read_sas(\"signals_raw_plus.sas7bdat\", encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df_original.copy()\n",
    "signals = signals_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "permnos = merged_df['permno'].unique()\n",
    "permno_to_gvkey = merged_df.set_index('permno')['gvkey'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert yyyymm to datetime\n",
    "merged_df['date'] = pd.to_datetime(merged_df['yyyymm'].astype(int).astype(str), format='%Y%m')\n",
    "merged_df['mktcap'] = merged_df['PRC'] * merged_df['SHROUT'] / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1497"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_df['permno'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3p/ssymn6xj7sl9h5r7vz8kp8ww0000gn/T/ipykernel_60436/3874959622.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  valid_permnos = january_data.groupby('permno').apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>yyyymm</th>\n",
       "      <th>monthid</th>\n",
       "      <th>ticker</th>\n",
       "      <th>conm</th>\n",
       "      <th>gvkey</th>\n",
       "      <th>cusip</th>\n",
       "      <th>naics</th>\n",
       "      <th>gsubind</th>\n",
       "      <th>IM</th>\n",
       "      <th>...</th>\n",
       "      <th>ret_f5</th>\n",
       "      <th>ret_f6</th>\n",
       "      <th>ret_f7</th>\n",
       "      <th>ret_f8</th>\n",
       "      <th>ret_f9</th>\n",
       "      <th>ret_f10</th>\n",
       "      <th>ret_f11</th>\n",
       "      <th>ret_f12</th>\n",
       "      <th>date</th>\n",
       "      <th>mktcap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>10104.0</td>\n",
       "      <td>198602.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.364103</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>-0.136364</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>-0.034884</td>\n",
       "      <td>0.301205</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>1986-02-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>10104.0</td>\n",
       "      <td>198603.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>-0.136364</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>-0.034884</td>\n",
       "      <td>0.301205</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>275.320375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>10104.0</td>\n",
       "      <td>198604.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>ORCL</td>\n",
       "      <td>ORACLE CORP</td>\n",
       "      <td>012142</td>\n",
       "      <td>68389X105</td>\n",
       "      <td>519130</td>\n",
       "      <td>45103020</td>\n",
       "      <td>0.636488</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136364</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>-0.034884</td>\n",
       "      <td>0.301205</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>1986-04-01</td>\n",
       "      <td>329.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>10104.0</td>\n",
       "      <td>198605.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>ORCL</td>\n",
       "      <td>ORACLE CORP</td>\n",
       "      <td>012142</td>\n",
       "      <td>68389X105</td>\n",
       "      <td>519130</td>\n",
       "      <td>45103020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>-0.034884</td>\n",
       "      <td>0.301205</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.159574</td>\n",
       "      <td>1986-05-01</td>\n",
       "      <td>309.941500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>10104.0</td>\n",
       "      <td>198606.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>ORCL</td>\n",
       "      <td>ORACLE CORP</td>\n",
       "      <td>012142</td>\n",
       "      <td>68389X105</td>\n",
       "      <td>519130</td>\n",
       "      <td>45103020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>-0.034884</td>\n",
       "      <td>0.301205</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.159574</td>\n",
       "      <td>-0.183486</td>\n",
       "      <td>1986-06-01</td>\n",
       "      <td>321.481875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       permno    yyyymm  monthid ticker         conm   gvkey      cusip  \\\n",
       "1224  10104.0  198602.0     74.0    NaN          NaN     NaN        NaN   \n",
       "1225  10104.0  198603.0     75.0    NaN          NaN     NaN        NaN   \n",
       "1226  10104.0  198604.0     76.0   ORCL  ORACLE CORP  012142  68389X105   \n",
       "1227  10104.0  198605.0     77.0   ORCL  ORACLE CORP  012142  68389X105   \n",
       "1228  10104.0  198606.0     78.0   ORCL  ORACLE CORP  012142  68389X105   \n",
       "\n",
       "       naics   gsubind        IM  ...    ret_f5    ret_f6    ret_f7    ret_f8  \\\n",
       "1224     NaN       NaN       NaN  ... -0.364103  0.064516 -0.136364  0.263158   \n",
       "1225     NaN       NaN       NaN  ...  0.064516 -0.136364  0.263158  0.194444   \n",
       "1226  519130  45103020  0.636488  ... -0.136364  0.263158  0.194444 -0.034884   \n",
       "1227  519130  45103020       NaN  ...  0.263158  0.194444 -0.034884  0.301205   \n",
       "1228  519130  45103020       NaN  ...  0.194444 -0.034884  0.301205  0.425926   \n",
       "\n",
       "        ret_f9   ret_f10   ret_f11   ret_f12       date      mktcap  \n",
       "1224  0.194444 -0.034884  0.301205  0.425926 1986-02-01         NaN  \n",
       "1225 -0.034884  0.301205  0.425926  0.142857 1986-03-01  275.320375  \n",
       "1226  0.301205  0.425926  0.142857  0.068182 1986-04-01  329.725000  \n",
       "1227  0.425926  0.142857  0.068182  0.159574 1986-05-01  309.941500  \n",
       "1228  0.142857  0.068182  0.159574 -0.183486 1986-06-01  321.481875  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "january_filter = (merged_df['date'].dt.month == 1)\n",
    "january_data = merged_df[january_filter]\n",
    "\n",
    "# Group by permno and check if any January data point has mkt_val or mktcap < 100\n",
    "valid_permnos = january_data.groupby('permno').apply(\n",
    "    lambda group: ((group['PRC'] > 5) & (group['mktcap'] >= 100)).all()\n",
    ")\n",
    "valid_permnos = valid_permnos[valid_permnos].index\n",
    "\n",
    "# Filter the dataframe to include only the valid permnos\n",
    "merged_df = merged_df[merged_df['permno'].isin(valid_permnos)]\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals.rename(columns={'PERMNO':'permno'}, inplace=True)\n",
    "signals['yyyymm'] = signals['fdate'].dt.strftime('%Y%m').astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(\n",
    "    merged_df, \n",
    "    signals, \n",
    "    on=['yyyymm', 'permno'], \n",
    "    how='inner',\n",
    "    suffixes=('', '_signals')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3p/ssymn6xj7sl9h5r7vz8kp8ww0000gn/T/ipykernel_60436/1942721390.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  missing_percentage = merged_df.groupby('permno').apply(\n"
     ]
    }
   ],
   "source": [
    "missing_percentage = merged_df.groupby('permno').apply(\n",
    "    lambda group: group.isnull().mean() * 100\n",
    ")\n",
    "# filter out companies that dont have 0% missing data for ticker in merged_df, meaning they might have been delisted or are newly listed\n",
    "valid_permnos = missing_percentage[missing_percentage['ticker'] == 0].index\n",
    "merged_df = merged_df[merged_df['permno'].isin(valid_permnos)]\n",
    "\n",
    "# for each permno, check if it has data for yyyymm starting from 199501\n",
    "valid_permnos = merged_df.groupby('permno')['yyyymm'].min().reset_index()\n",
    "valid_permnos = valid_permnos[valid_permnos['yyyymm'] <= 199501]['permno']\n",
    "merged_df = merged_df[merged_df['permno'].isin(valid_permnos)]\n",
    "\n",
    "# for each permno, check if it has data for yyyymm that ends in 201912\n",
    "valid_permnos = merged_df.groupby('permno')['yyyymm'].max().reset_index()\n",
    "valid_permnos = valid_permnos[valid_permnos['yyyymm'] >= 201912]['permno']\n",
    "merged_df = merged_df[merged_df['permno'].isin(valid_permnos)]\n",
    "print(valid_permnos.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Reversion Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mean reversion signal by calculating rolling z-scores of returns\n",
    "def calculate_z_score(series):\n",
    "    # Convert numpy array to pandas Series if needed\n",
    "    if isinstance(series, np.ndarray):\n",
    "        series = pd.Series(series)\n",
    "    \n",
    "    if len(series) == 0 or series.isna().all():\n",
    "        return np.nan\n",
    "    mean = series.mean()\n",
    "    std = series.std()\n",
    "    # Handle division by zero\n",
    "    if std == 0:\n",
    "        return np.nan\n",
    "    # Return the z-score of the last value in the series\n",
    "    return (series.iloc[-1] - mean) / std\n",
    "\n",
    "# Sort dataframe by permno and date for proper time series analysis\n",
    "merged_df = merged_df.sort_values(['permno', 'yyyymm'])\n",
    "\n",
    "# Calculate returns by permno\n",
    "merged_df['ret'] = merged_df.groupby('permno')['PRC'].pct_change()\n",
    "\n",
    "# Create rolling z-scores by permno\n",
    "z_scores = []\n",
    "for permno, group in merged_df.groupby('permno'):\n",
    "    group = group.sort_values('yyyymm')\n",
    "    group['rolling_z_score'] = group['ret'].rolling(window=36).apply(calculate_z_score, raw=False)\n",
    "    z_scores.append(group)\n",
    "\n",
    "# Combine results\n",
    "merged_df = pd.concat(z_scores)\n",
    "\n",
    "# Clean up z-scores\n",
    "merged_df['rolling_z_score'] = merged_df['rolling_z_score'].fillna(0)\n",
    "merged_df['rolling_z_score'] = merged_df['rolling_z_score'].replace([np.inf, -np.inf], 0)\n",
    "\n",
    "# Create mean reversion signal\n",
    "merged_df['mean_reversion_signal'] = np.where(\n",
    "    merged_df['rolling_z_score'] > 1, -1,\n",
    "    np.where(merged_df['rolling_z_score'] < -1, 1, 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Macro Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Macro Uncertainty\n",
    "macro_uncertainty_original = pd.read_sas(\"macro.sas7bdat\", encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_uncertainty = macro_uncertainty_original.copy()\n",
    "macro_uncertainty[\"yyyymm\"] = macro_uncertainty[\"date\"].dt.strftime('%Y%m').astype(int)\n",
    "macro_uncertainty.set_index(\"yyyymm\", inplace=True)\n",
    "\n",
    "merged_df = pd.merge(\n",
    "    merged_df,\n",
    "    macro_uncertainty,\n",
    "    left_on=\"yyyymm\",\n",
    "    right_index=True,\n",
    "    how=\"left\",\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    permno    yyyymm  monthid ticker         conm   gvkey      cusip   naics  \\\n",
      "0  10104.0  199501.0    181.0   ORCL  ORACLE CORP  012142  68389X105  519130   \n",
      "1  10104.0  199502.0    182.0   ORCL  ORACLE CORP  012142  68389X105  519130   \n",
      "2  10104.0  199503.0    183.0   ORCL  ORACLE CORP  012142  68389X105  519130   \n",
      "3  10104.0  199504.0    184.0   ORCL  ORACLE CORP  012142  68389X105  519130   \n",
      "4  10104.0  199505.0    185.0   ORCL  ORACLE CORP  012142  68389X105  519130   \n",
      "\n",
      "    gsubind        IM  ...  sales_g_ttm_winsorized  LiqVol_winsorized  \\\n",
      "0  45103020 -0.015804  ...                0.404471                NaN   \n",
      "1  45103020 -0.034445  ...                0.404471                NaN   \n",
      "2  45103020 -0.007065  ...                0.404471                NaN   \n",
      "3  45103020  0.005445  ...                0.449430                NaN   \n",
      "4  45103020  0.031876  ...                0.449430                NaN   \n",
      "\n",
      "   dp_winsorized  sales_g_q_winsorized  SIR_winsorized  xret_20_winsorized  \\\n",
      "0            0.0              0.482363             NaN            0.064046   \n",
      "1            0.0              0.482363             NaN           -0.024746   \n",
      "2            0.0              0.482363             NaN            0.079822   \n",
      "3            0.0              0.495982             NaN           -0.077545   \n",
      "4            0.0              0.495982             NaN           -0.042319   \n",
      "\n",
      "   ATG_winsorized  QUICK_winsorized  ret_f12_winsorized  CAPEC_winsorized  \n",
      "0       -0.446386         -1.437363            0.126844          0.018830  \n",
      "1       -0.446386         -1.437363            0.089005          0.016994  \n",
      "2       -0.446386         -1.437363           -0.093750          0.017062  \n",
      "3       -0.471579         -1.437363            0.074271          0.019455  \n",
      "4       -0.471579         -1.437363           -0.018519          0.016992  \n",
      "\n",
      "[5 rows x 403 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felix\\AppData\\Local\\Temp\\ipykernel_39100\\913607033.py:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  merged_df = merged_df.groupby('monthid', group_keys=False).apply(winsorize)\n"
     ]
    }
   ],
   "source": [
    "# Winsorization using groupby and vectorized operations\n",
    "non_data_cols = {'permno', 'yyyymm', 'monthid', 'ticker', 'conm', 'gvkey', 'cusip', 'naics', 'gsubind', 'PRC', 'VOL', 'RET', 'SHROUT'}\n",
    "data_cols = set(merged_df.columns) - non_data_cols\n",
    "# Winsorization using groupby and avoiding fragmentation\n",
    "def winsorize(group):\n",
    "    group = group.copy()  # Avoid modifying the original group\n",
    "    winsorized_data = {}  # Collect winsorized columns here\n",
    "    for column in data_cols:\n",
    "        lower_quantile = group[column].quantile(0.01)\n",
    "        upper_quantile = group[column].quantile(0.99)\n",
    "        winsorized_data[f'{column}_winsorized'] = group[column].clip(lower=lower_quantile, upper=upper_quantile)\n",
    "    # Combine the original group with the new winsorized columns\n",
    "    winsorized_df = pd.concat([group, pd.DataFrame(winsorized_data, index=group.index)], axis=1)\n",
    "    return winsorized_df\n",
    "\n",
    "# Apply Winsorization by grouping on 'monthid'\n",
    "merged_df = merged_df.groupby('monthid', group_keys=False).apply(winsorize)\n",
    "\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
